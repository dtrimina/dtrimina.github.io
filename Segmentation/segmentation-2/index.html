<!DOCTYPE html><html lang="en"><head><meta name="generator" content="Hexo 3.8.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="learning CNNs and deep learning"><title>segmentation(2) -- U-Net、SegNet | LXY</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.4.0/jquery.min.js"></script><link rel="icon" mask sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">segmentation(2) -- U-Net、SegNet</h1><a id="logo" href="/.">LXY</a><p class="description">deep learning tutorial</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> Home</i></a><a href="/archives/"><i class="fa fa-archive"> Archive</i></a><a href="/about/"><i class="fa fa-user"> About</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">segmentation(2) -- U-Net、SegNet</h1><div class="post-meta">Sep 24, 2019<span> | </span><span class="category"><a href="/categories/Segmentation/">Segmentation</a></span></div><div class="post-content"><p>paper: <a href="http://xxx.itp.ac.cn/pdf/1505.04597.pdf" target="_blank" rel="noopener">U-Net: Convolutional Networks for Biomedical Image Segmentation</a></p>
<h5 id="总体结构"><a href="#总体结构" class="headerlink" title="总体结构"></a>总体结构</h5><div align="center"><img src="https://saveimages.oss-cn-hangzhou.aliyuncs.com/Segmentation/U-Net/unet_architecture.png" height="70%" width="70%"></div>

<p>1.输入使用镜像边缘填充。图像大小为512x512，边缘镜像翻转30pixel，则输入图像尺寸变为572x572.</p>
<div align="center"><img src="https://saveimages.oss-cn-hangzhou.aliyuncs.com/Segmentation/U-Net/mirror_padding.jpg" height="50%" width="50%"></div>

<p>2.网络中的卷积不使用padding，编码部分和解码部分尺寸不对应，特征拼接时需要centercrop。<br>3.输出为2通道，使用二分类cross entropy。考虑到让网络能学习到紧邻的两个细胞间的边界，每个pixel的loss需要乘以weight map对应的权重。如下图d，紧邻的两个细胞间的边界部分有较高的权重。</p>
<div align="center"><img src="https://saveimages.oss-cn-hangzhou.aliyuncs.com/Segmentation/U-Net/weight_loss.jpg" height="70%" width="70%"></div>

<p>$$<br>E=\sum_{\mathbf{x} \in \Omega} w(\mathbf{x}) \log \left(p_{\ell(\mathbf{x})}(\mathbf{x})\right)<br>$$<br>$$<br>w(\mathbf{x})=w_{c}(\mathbf{x})+w_{0} \cdot \exp \left(-\frac{\left(d_{1}(\mathbf{x})+d_{2}(\mathbf{x})\right)^{2}}{2 \sigma^{2}}\right)<br>$$</p>
<p>其中$w_{c}$是平衡类别比例的权值，$d_{1}$是像素点到距离其最近的细胞的距离，$d_{2}$是像素点到距离其第二近的细胞的距离。$w_{0}$和l$\delta$是常数值。</p>
<hr>
<p>paper: <a href="http://xxx.itp.ac.cn/pdf/1511.00561.pdf" target="_blank" rel="noopener">SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation</a></p>
<h5 id="总体结构-1"><a href="#总体结构-1" class="headerlink" title="总体结构"></a>总体结构</h5><div align="center"><img src="https://saveimages.oss-cn-hangzhou.aliyuncs.com/Segmentation/SegNet/segnet_architecture.jpg" height="70%" width="70%"></div>

<ul>
<li>使用encoder-decoder结构，编码部分使用预训练VGG16.</li>
<li>编码时需要保存maxpooling的位置信息(每个pixel使用2bit存储信息)，供解码时上采样使用。</li>
<li>和<a href="https://blog.dtrimina.cn/Segmentation/segmentation-1/">DecovNet</a>不同的是，Segnet不使用VGG16的全连接层，全连接层包含的大量参数，因此Segnet比DecovNet参数少很多。</li>
<li>使用cross-entropy loss，考虑median frequency balancing类别平衡。</li>
</ul>
</div><div class="tags"><a href="/tags/Segmentation/">Segmentation</a></div><div class="post-nav"><a class="pre" href="/Segmentation/segmentation-3/">segmentation(3) -- ENet、LinkNet、FC-DenseNet</a><a class="next" href="/Classification/classification-4/">Inceptions -- GoogLeNet, V2, V3, V4</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"><input type="hidden" name="sitesearch" value="https://blog.dtrimina.cn"></form></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> Tags</i></div><div class="tagcloud"><a href="/tags/deep-learning-tools/" style="font-size: 15px;">deep-learning-tools</a> <a href="/tags/Classification/" style="font-size: 15px;">Classification</a> <a href="/tags/Detection/" style="font-size: 15px;">Detection</a> <a href="/tags/Segmentation/" style="font-size: 15px;">Segmentation</a> <a href="/tags/summary/" style="font-size: 15px;">summary</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> Recent</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/Segmentation/segmentation-4/">segmentation(4) -- DilatedNet、DRN</a></li><li class="post-list-item"><a class="post-list-link" href="/Segmentation/segmentation-3/">segmentation(3) -- ENet、LinkNet、FC-DenseNet</a></li><li class="post-list-item"><a class="post-list-link" href="/Segmentation/segmentation-2/">segmentation(2) -- U-Net、SegNet</a></li><li class="post-list-item"><a class="post-list-link" href="/Classification/classification-4/">Inceptions -- GoogLeNet, V2, V3, V4</a></li><li class="post-list-item"><a class="post-list-link" href="/Segmentation/segmentation-1/">segmentation(1) -- FCN、DeconvNet</a></li><li class="post-list-item"><a class="post-list-link" href="/summary/CNN-architecture-summary/">Systematic evaluation of CNN advances on the ImageNet</a></li><li class="post-list-item"><a class="post-list-link" href="/Classification/SqueezeNet/">SqueezeNet</a></li><li class="post-list-item"><a class="post-list-link" href="/deep-learning-tools/Ubuntu18-04-deep-learning/">Ubuntu18.04 with deep learning (cuda10.0 + pytorch1.1 + tensorflow2.0.0-beta + mxnet)</a></li><li class="post-list-item"><a class="post-list-link" href="/Detection/Fast-RCNN/">Fast R-CNN</a></li><li class="post-list-item"><a class="post-list-link" href="/Classification/classification-3/">classification(3) -- VGG、Resnet、GoogLeNet、SPP-net</a></li></ul></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2019 <a href="/." rel="nofollow">LXY.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>