<!DOCTYPE html><html lang="en"><head><meta name="generator" content="Hexo 3.8.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="learning CNNs and deep learning"><title>Systematic evaluation of CNN advances on the ImageNet | LXY</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.4.0/jquery.min.js"></script><link rel="icon" mask sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Systematic evaluation of CNN advances on the ImageNet</h1><a id="logo" href="/.">LXY</a><p class="description">deep learning tutorial</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> Home</i></a><a href="/archives/"><i class="fa fa-archive"> Archive</i></a><a href="/about/"><i class="fa fa-user"> About</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Systematic evaluation of CNN advances on the ImageNet</h1><div class="post-meta">Jul 18, 2019<span> | </span><span class="category"><a href="/categories/summary/">summary</a></span></div><div class="post-content"><p>paper: <a href="http://xxx.itp.ac.cn/pdf/1606.02228v2" target="_blank" rel="noopener">Systematic evaluation of CNN advances on the ImageNet</a> </p>
<p>The paper systematically studies the impact of a range of recent advances in CNN architectures and learning methods on the object categorization (ILSVRC) problem. The evalution tests the influence of the following choices of the architecture: </p>
<ul>
<li>non-linearity (ReLU, ELU, maxout, compatability with batch normalization);</li>
<li>pooling variants (stochastic, max, average, mixed); </li>
<li>network width;</li>
<li>classifier design (convolutional, fully-connected, SPP);</li>
<li>image pre-processing;</li>
<li>learning parameters: learning rate, batch size, cleanliness of the data.<br>The paper uses 128x128 pixel images for saving time which is sufficient to make qualitative conclusions about optimal network structure.</li>
</ul>
<h3 id="Evaluation-framework"><a href="#Evaluation-framework" class="headerlink" title="Evaluation framework"></a><strong>Evaluation framework</strong></h3><p>The commonly used pre-processing includes image rescaling to 256xN, where N ≥ 256, and then cropping a random 224x224<br>square,but we limit the image size to 144xN where N ≥ 128 (denoted as ImageNet-128px) to save training time. The test parameters and 2x tinner CaffeNet are as follows.</p>
<div align="center"><img src="https://saveimages.oss-cn-hangzhou.aliyuncs.com/CNNs_for_image_classification/CNN-architecture-summary/hyper_parameters.png" height="70%" width="70%"></div><br><div align="center"><img src="https://saveimages.oss-cn-hangzhou.aliyuncs.com/CNNs_for_image_classification/CNN-architecture-summary/basic_CaffeNet.png" height="70%" width="70%"></div>  

<h3 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a><strong>Experiment</strong></h3><h5 id="Activation-functions"><a href="#Activation-functions" class="headerlink" title="Activation functions"></a><strong>Activation functions</strong></h5><div align="center"><img src="https://saveimages.oss-cn-hangzhou.aliyuncs.com/CNNs_for_image_classification/CNN-architecture-summary/activation_compare.png" height="70%" width="70%"></div>  

<ul>
<li>The best single performing activation function similar in complexity to ReLU is ELU.</li>
<li>Wide maxout outperforms the rest of the competitors at a higher computational cost.</li>
</ul>
<h5 id="Pooling"><a href="#Pooling" class="headerlink" title="Pooling"></a><strong>Pooling</strong></h5><div align="center"><img src="https://saveimages.oss-cn-hangzhou.aliyuncs.com/CNNs_for_image_classification/CNN-architecture-summary/pooling_test.png" height="70%" width="70%"></div><br><div align="center"><img src="https://saveimages.oss-cn-hangzhou.aliyuncs.com/CNNs_for_image_classification/CNN-architecture-summary/pooling_results.png" height="70%" width="70%"></div>  

<ul>
<li>The best results were obtained by a combination of max and average pooling.</li>
</ul>
<h5 id="Learning-rate-policy"><a href="#Learning-rate-policy" class="headerlink" title="Learning rate policy"></a><strong>Learning rate policy</strong></h5><div align="center"><img src="https://saveimages.oss-cn-hangzhou.aliyuncs.com/CNNs_for_image_classification/CNN-architecture-summary/lr_decay_policies.png" height="70%" width="70%"></div><br><div align="center"><img src="https://saveimages.oss-cn-hangzhou.aliyuncs.com/CNNs_for_image_classification/CNN-architecture-summary/lr_compare.png" height="70%" width="70%"></div>  

<ul>
<li><strong>Learning rate is very important</strong>.</li>
<li>“reduce learning rate 10x, when validation error stops decreasing” is the most commonly used learning rate decay policy, but <strong>linear decay</strong> gives the best results. </li>
</ul>
<h5 id="Image-pre-processing"><a href="#Image-pre-processing" class="headerlink" title="Image pre-processing"></a><strong>Image pre-processing</strong></h5><div align="center"><img src="https://saveimages.oss-cn-hangzhou.aliyuncs.com/CNNs_for_image_classification/CNN-architecture-summary/learn_transform.png" height="70%" width="70%"></div><br><div align="center"><img src="https://saveimages.oss-cn-hangzhou.aliyuncs.com/CNNs_for_image_classification/CNN-architecture-summary/color_compare.png" height="70%" width="70%"></div>

<ul>
<li>RGB is the best suitable colorspace for CNNs</li>
<li>to learn a transformation which can be seen as extending the CaffeNet architecture with several 1x1 convolutions at the input can improve the performance.</li>
</ul>
<h5 id="Batch-normalization"><a href="#Batch-normalization" class="headerlink" title="Batch normalization"></a><strong>Batch normalization</strong></h5><ul>
<li>solve the gradient exploding/vanishing problem and guarantees near-optimal learning regime for the layer following the batch normalized one.</li>
<li>it works well in CaffeNet and VGG, but not good in GoogLeNet</li>
</ul>
<h5 id="Classifier-design"><a href="#Classifier-design" class="headerlink" title="Classifier design"></a><strong>Classifier design</strong></h5><h5 id="Batch-size-and-learning-rate"><a href="#Batch-size-and-learning-rate" class="headerlink" title="Batch size and learning rate"></a><strong>Batch size and learning rate</strong></h5><div align="center"><img src="https://saveimages.oss-cn-hangzhou.aliyuncs.com/CNNs_for_image_classification/CNN-architecture-summary/lr_and_batchsize_compare.png" height="70%" width="70%"></div>

<ul>
<li>keeping a constant learning rate for different mini-batch sizes has a negative impact on performance.</li>
<li>large (512 and more) mini-batch sizes leads to quite significant decrease in performance.</li>
</ul>
<h5 id="Network-width"><a href="#Network-width" class="headerlink" title="Network width"></a><strong>Network width</strong></h5><h5 id="Input-image-size"><a href="#Input-image-size" class="headerlink" title="Input image size"></a><strong>Input image size</strong></h5><h5 id="Dataset-size-and-noisy-labels"><a href="#Dataset-size-and-noisy-labels" class="headerlink" title="Dataset size and noisy labels"></a><strong>Dataset size and noisy labels</strong></h5><h5 id="Bias-in-convolution-layers"><a href="#Bias-in-convolution-layers" class="headerlink" title="Bias in convolution layers"></a><strong>Bias in convolution layers</strong></h5><h3 id="Conclusions"><a href="#Conclusions" class="headerlink" title="Conclusions"></a><strong>Conclusions</strong></h3><ul>
<li>use ELU non-linearity without batchnorm or ReLU with it.</li>
<li>apply a learned colorspace transformation of RGB.</li>
<li>use the linear learning rate decay policy.</li>
<li>use a sum of the average and max pooling layers.</li>
<li>use mini-batch size around 128 or 256. If this is too big for your GPU, decrease the learning rate proportionally to the batch size.</li>
<li>use fully-connected layers as convolutional and average the predictions for the final decision.</li>
<li>when investing in increasing training set size, check if a plateau has not been reach.</li>
<li>cleanliness of the data is more important then the size.</li>
<li>if you cannot increase the input image size, reduce the stride in the consequent layers, it has roughly the same effect.</li>
<li>if your network has a complex and highly optimized architecture, like e.g. GoogLeNet, be careful with modifications.</li>
</ul>
</div><div class="tags"><a href="/tags/Classification/">Classification</a><a href="/tags/summary/">summary</a></div><div class="post-nav"><a class="pre" href="/Segmentation/segmentation-1/">segmentation(1) -- FCN、DeconvNet</a><a class="next" href="/Classification/SqueezeNet/">SqueezeNet</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"><input type="hidden" name="sitesearch" value="https://blog.dtrimina.cn"></form></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> Tags</i></div><div class="tagcloud"><a href="/tags/deep-learning-tools/" style="font-size: 15px;">deep-learning-tools</a> <a href="/tags/Classification/" style="font-size: 15px;">Classification</a> <a href="/tags/Detection/" style="font-size: 15px;">Detection</a> <a href="/tags/Segmentation/" style="font-size: 15px;">Segmentation</a> <a href="/tags/summary/" style="font-size: 15px;">summary</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> Recent</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/Segmentation/segmentation-4/">segmentation(4) -- DilatedNet、DRN</a></li><li class="post-list-item"><a class="post-list-link" href="/Segmentation/segmentation-3/">segmentation(3) -- ENet、LinkNet、FC-DenseNet</a></li><li class="post-list-item"><a class="post-list-link" href="/Segmentation/segmentation-2/">segmentation(2) -- U-Net、SegNet</a></li><li class="post-list-item"><a class="post-list-link" href="/Classification/classification-4/">Inceptions -- GoogLeNet, V2, V3, V4</a></li><li class="post-list-item"><a class="post-list-link" href="/Segmentation/segmentation-1/">segmentation(1) -- FCN、DeconvNet</a></li><li class="post-list-item"><a class="post-list-link" href="/summary/CNN-architecture-summary/">Systematic evaluation of CNN advances on the ImageNet</a></li><li class="post-list-item"><a class="post-list-link" href="/Classification/SqueezeNet/">SqueezeNet</a></li><li class="post-list-item"><a class="post-list-link" href="/deep-learning-tools/Ubuntu18-04-deep-learning/">Ubuntu18.04 with deep learning (cuda10.0 + pytorch1.1 + tensorflow2.0.0-beta + mxnet)</a></li><li class="post-list-item"><a class="post-list-link" href="/Detection/Fast-RCNN/">Fast R-CNN</a></li><li class="post-list-item"><a class="post-list-link" href="/Classification/classification-3/">classification(3) -- VGG、Resnet、GoogLeNet、SPP-net</a></li></ul></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2019 <a href="/." rel="nofollow">LXY.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>