<!DOCTYPE html><html lang="en"><head><meta name="generator" content="Hexo 3.8.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="learning CNNs and deep learning"><title>Inceptions -- GoogLeNet, V2, V3, V4 | LXY</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.4.0/jquery.min.js"></script><link rel="icon" mask sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Inceptions -- GoogLeNet, V2, V3, V4</h1><a id="logo" href="/.">LXY</a><p class="description">deep learning tutorial</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> Home</i></a><a href="/archives/"><i class="fa fa-archive"> Archive</i></a><a href="/about/"><i class="fa fa-user"> About</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Inceptions -- GoogLeNet, V2, V3, V4</h1><div class="post-meta">Sep 18, 2019<span> | </span><span class="category"><a href="/categories/Classification/">Classification</a></span></div><div class="post-content"><p>paper: <a href="https://arxiv.org/pdf/1409.4842.pdf" target="_blank" rel="noopener">Going deeper with convolutions</a></p>
<h5 id="Inception-V1-GoogLeNet"><a href="#Inception-V1-GoogLeNet" class="headerlink" title="Inception-V1 GoogLeNet"></a>Inception-V1 <a href="https://blog.dtrimina.cn/Classification/GoogLeNet/">GoogLeNet</a></h5><hr>
<p>paper: <a href="https://arxiv.org/pdf/1512.00567.pdf" target="_blank" rel="noopener">Rethinking the Inception Architecture for Computer Vision</a></p>
<h5 id="Inception-v2，v3"><a href="#Inception-v2，v3" class="headerlink" title="Inception-v2，v3"></a>Inception-v2，v3</h5><p>新的Inceptionv3结构如下，论文在Inception-v2(<a href="https://blog.dtrimina.cn/Classification/Batch-Normalization/">BN-Inception</a>)的基础上进行一些改进。</p>
<div align="center"><img src="https://saveimages.oss-cn-hangzhou.aliyuncs.com/CNNs_for_image_classification/Inception_v3/inceptionv3_architecture.jpg" height="60%" width="60%"></div>

<p>其中三种Inception结构如下</p>
<div align="center"><img src="https://saveimages.oss-cn-hangzhou.aliyuncs.com/CNNs_for_image_classification/Inception_v3/InceptionA.jpg" height="40%" width="40%"></div><br><div align="center"><img src="https://saveimages.oss-cn-hangzhou.aliyuncs.com/CNNs_for_image_classification/Inception_v3/InceptionB.jpg" height="40%" width="40%"></div><br><div align="center"><img src="https://saveimages.oss-cn-hangzhou.aliyuncs.com/CNNs_for_image_classification/Inception_v3/InceptionC.jpg" height="40%" width="40%"></div>


<p>1.将大尺寸卷积分解为小尺寸卷积的堆叠。(e.g. 5x5卷积使用两个3x3卷积堆叠代替)<br>2.卷积操作的进一步分解。(e.g. 3x3卷积使用3x1卷积和1x3卷积堆叠代替)<br>3.辅助分类器中使用BatchNorm和Dropout性能会更好。<br>4.先进行Pooling再通过Inception模块，训练参数较少但模型表征能力变弱；先通过Inception模块再进行Pooling，训练参数会稍增加，但模型具有更好的表征能力。一个折中的方案如下所示，It is both cheap and avoids the representational bottleneck. </p>
<div align="center"><img src="https://saveimages.oss-cn-hangzhou.aliyuncs.com/CNNs_for_image_classification/Inception_v3/reducing_grid_size.jpg" height="50%" width="50%"></div>  

<p>5.label-smoothing regularization<br>比较结果如下，应用以上所有性质的Inception称为Inceptionv3.  </p>
<div align="center"><img src="https://saveimages.oss-cn-hangzhou.aliyuncs.com/CNNs_for_image_classification/Inception_v3/Inceptionv3_results.jpg" height="50%" width="50%"></div>  

<hr>
<p>paper: <a href="https://arxiv.org/pdf/1602.07261.pdf" target="_blank" rel="noopener">Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning</a></p>
<h5 id="Inception-V4"><a href="#Inception-V4" class="headerlink" title="Inception-V4"></a>Inception-V4</h5><p>总体结构如下：</p>
<div align="center"><img src="https://saveimages.oss-cn-hangzhou.aliyuncs.com/CNNs_for_image_classification/Inception_v4/inception_v4_architecture.jpg" height="40%" width="40%"></div><br>其中各模块参考论文：<br><br>- Stem -&gt; Figure 3<br>- Inception-A -&gt; Figure 4<br>- Reduction-A -&gt; Figure 7<br>- Inception-B -&gt; Figure 5<br>- Reduction-B -&gt; Figure 8<br>- Inception-C -&gt; Figure 6<br><br><br>##### Inception-ResNets<br>总体结构如下：<br><div align="center"><img src="https://saveimages.oss-cn-hangzhou.aliyuncs.com/CNNs_for_image_classification/Inception_v4/Inception_resnets.jpg" height="40%" width="40%"></div>   

<ul>
<li>Inception-ResNet-v1和Inceptionv3计算量相似，各模块参考Figure 14、10、7、11、12、13  </li>
<li>Inception-ResNet-v2和Inceptionv4计算量相似，各模块参考Figure 3、16、7、17、18、19  </li>
</ul>
<p>一些结果比较如下：  </p>
<div align="center"><img src="https://saveimages.oss-cn-hangzhou.aliyuncs.com/CNNs_for_image_classification/Inception_v4/result1.jpg" height="50%" width="50%"></div><br><div align="center"><img src="https://saveimages.oss-cn-hangzhou.aliyuncs.com/CNNs_for_image_classification/Inception_v4/result2.jpg" height="50%" width="50%"></div><br><div align="center"><img src="https://saveimages.oss-cn-hangzhou.aliyuncs.com/CNNs_for_image_classification/Inception_v4/result3.jpg" height="50%" width="50%"></div><br><div align="center"><img src="https://saveimages.oss-cn-hangzhou.aliyuncs.com/CNNs_for_image_classification/Inception_v4/result4.jpg" height="50%" width="50%"></div>   
</div><div class="tags"><a href="/tags/Classification/">Classification</a></div><div class="post-nav"><a class="pre" href="/Segmentation/segmentation-2/">segmentation(2) -- U-Net、SegNet</a><a class="next" href="/Segmentation/segmentation-1/">segmentation(1) -- FCN、DeconvNet</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"><input type="hidden" name="sitesearch" value="https://blog.dtrimina.cn"></form></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> Tags</i></div><div class="tagcloud"><a href="/tags/deep-learning-tools/" style="font-size: 15px;">deep-learning-tools</a> <a href="/tags/Classification/" style="font-size: 15px;">Classification</a> <a href="/tags/Detection/" style="font-size: 15px;">Detection</a> <a href="/tags/Segmentation/" style="font-size: 15px;">Segmentation</a> <a href="/tags/summary/" style="font-size: 15px;">summary</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> Recent</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/Segmentation/segmentation-4/">segmentation(4) -- DilatedNet、DRN</a></li><li class="post-list-item"><a class="post-list-link" href="/Segmentation/segmentation-3/">segmentation(3) -- ENet、LinkNet、FC-DenseNet</a></li><li class="post-list-item"><a class="post-list-link" href="/Segmentation/segmentation-2/">segmentation(2) -- U-Net、SegNet</a></li><li class="post-list-item"><a class="post-list-link" href="/Classification/classification-4/">Inceptions -- GoogLeNet, V2, V3, V4</a></li><li class="post-list-item"><a class="post-list-link" href="/Segmentation/segmentation-1/">segmentation(1) -- FCN、DeconvNet</a></li><li class="post-list-item"><a class="post-list-link" href="/summary/CNN-architecture-summary/">Systematic evaluation of CNN advances on the ImageNet</a></li><li class="post-list-item"><a class="post-list-link" href="/Classification/SqueezeNet/">SqueezeNet</a></li><li class="post-list-item"><a class="post-list-link" href="/deep-learning-tools/Ubuntu18-04-deep-learning/">Ubuntu18.04 with deep learning (cuda10.0 + pytorch1.1 + tensorflow2.0.0-beta + mxnet)</a></li><li class="post-list-item"><a class="post-list-link" href="/Detection/Fast-RCNN/">Fast R-CNN</a></li><li class="post-list-item"><a class="post-list-link" href="/Classification/classification-3/">classification(3) -- VGG、Resnet、GoogLeNet、SPP-net</a></li></ul></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2019 <a href="/." rel="nofollow">LXY.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>