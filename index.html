<!DOCTYPE html><html lang="en"><head><meta name="generator" content="Hexo 3.8.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="learning CNNs and deep learning"><title>LXY | deep learning tutorial</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.4.0/jquery.min.js"></script><link rel="icon" mask sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">LXY</h1><a id="logo" href="/.">LXY</a><p class="description">deep learning tutorial</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> Home</i></a><a href="/archives/"><i class="fa fa-archive"> Archive</i></a><a href="/about/"><i class="fa fa-user"> About</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title"><a href="/Segmentation/segmentation-1/">segmentation(1) -- FCN、DeconvNet</a></h1><div class="post-meta">2019-09-11</div><div class="post-content"><p>paper: <a href="http://xxx.itp.ac.cn/pdf/1605.06211.pdf" target="_blank" rel="noopener">Fully Convolutional Networks for Semantic Segmentation</a></p></div><p class="readmore"><a href="/Segmentation/segmentation-1/">Read More</a></p></div><div class="post"><h1 class="post-title"><a href="/summary/CNN-architecture-summary/">Systematic evaluation of CNN advances on the ImageNet</a></h1><div class="post-meta">2019-07-18</div><div class="post-content"><p>paper: <a href="http://xxx.itp.ac.cn/pdf/1606.02228v2" target="_blank" rel="noopener">Systematic evaluation of CNN advances on the ImageNet</a> </p></div><p class="readmore"><a href="/summary/CNN-architecture-summary/">Read More</a></p></div><div class="post"><h1 class="post-title"><a href="/CNNs-for-classification/SqueezeNet/">SqueezeNet</a></h1><div class="post-meta">2019-07-15</div><div class="post-content"><p>paper: <a href="http://xxx.itp.ac.cn/pdf/1602.07360v4" target="_blank" rel="noopener">SQUEEZENET: ALEXNET-LEVEL ACCURACY WITH 50X FEWER PARAMETERS AND &lt;0.5MB MODEL SIZE</a> with <a href="https://github.com/weiaicunzai/pytorch-cifar100/blob/master/models/squeezenet.py" target="_blank" rel="noopener">pytorch code</a></p></div><p class="readmore"><a href="/CNNs-for-classification/SqueezeNet/">Read More</a></p></div><div class="post"><h1 class="post-title"><a href="/deep-learning-tools/Ubuntu18-04-deep-learning/">Ubuntu18.04 with deep learning (cuda10.0 + pytorch1.1 + tensorflow2.0.0-beta + mxnet)</a></h1><div class="post-meta">2019-07-01</div><div class="post-content"><h4 id="1-install-Ubuntu18-04-and-update-source"><a href="#1-install-Ubuntu18-04-and-update-source" class="headerlink" title="1.install Ubuntu18.04 and update source"></a>1.install Ubuntu18.04 and update source</h4><p>Update to mirrors.aliyun.com, reference <a href="https://blog.csdn.net/hymanjack/article/details/80285400" target="_blank" rel="noopener">this</a> in step 1.</p></div><p class="readmore"><a href="/deep-learning-tools/Ubuntu18-04-deep-learning/">Read More</a></p></div><div class="post"><h1 class="post-title"><a href="/CNNs-for-classification/Resnet/">Resnet</a></h1><div class="post-meta">2019-06-27</div><div class="post-content"><p>paper: <a href="http://xxx.itp.ac.cn/pdf/1512.03385" target="_blank" rel="noopener">Deep Residual Learning for Image Recognition</a>  </p>
<h3 id="degradation-problem"><a href="#degradation-problem" class="headerlink" title="degradation problem"></a><strong>degradation problem</strong></h3><p>what is the problem ?<br>with the network depth increasing, accuracy gets saturated (which might be unsurprising) and then degrades rapidly, just as shown below. such degradation is <strong>not caused by overfitting</strong>.  </p></div><p class="readmore"><a href="/CNNs-for-classification/Resnet/">Read More</a></p></div><div class="post"><h1 class="post-title"><a href="/CNNs-for-detection/Fast-RCNN/">Fast R-CNN</a></h1><div class="post-meta">2019-06-21</div><div class="post-content"><p>paper: <a href="http://xxx.itp.ac.cn/pdf/1504.08083v2" target="_blank" rel="noopener">Fast R-CNN</a></p>
<p><a href="https://blog.dtrimina.cn/CNNs-for-classification/SPP-net/">SPPnet</a> solved the R-CNN’s problem that it extracts features for each of the 2k~ region proposal and costs a lot of time. SPPnet runs the convolutional layers only once on the entire image (regardless of the number of windows), and then extract features by SPP-net on the feature maps. But it is <strong>not an end-to-end model</strong> so that extracted features need to be written to the disk, and uses two stages for classification and bbox regression. Fast R-CNN can do back-propagation end-to-end.</p></div><p class="readmore"><a href="/CNNs-for-detection/Fast-RCNN/">Read More</a></p></div><div class="post"><h1 class="post-title"><a href="/CNNs-for-classification/SPP-net/">SPP-net</a></h1><div class="post-meta">2019-06-19</div><div class="post-content"><p>paper: <a href="https://arxiv.org/pdf/1905.09646.pdf" target="_blank" rel="noopener">Spatial Group-wise Enhance: Improving Semantic Feature Learning in Convolutional Networks</a></p></div><p class="readmore"><a href="/CNNs-for-classification/SPP-net/">Read More</a></p></div><div class="post"><h1 class="post-title"><a href="/CNNs-for-classification/PReLU-nets/">PReLU-nets</a></h1><div class="post-meta">2019-06-01</div><div class="post-content"><p>paper: <a href="https://arxiv.org/pdf/1502.01852.pdf" target="_blank" rel="noopener">Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification</a></p></div><p class="readmore"><a href="/CNNs-for-classification/PReLU-nets/">Read More</a></p></div><div class="post"><h1 class="post-title"><a href="/CNNs-for-classification/Highway-Networks/">Highway Networks</a></h1><div class="post-meta">2019-05-31</div><div class="post-content"><p>paper: <a href="https://arxiv.org/pdf/1505.00387.pdf" target="_blank" rel="noopener">Highway Networks</a>  </p>
<p>It is well known that deep networks can represent certain function classes exponentially more efficiently than shallow ones. However, network training becomes more difficult with increasing depth and training of very deep networks. Inspired by LSTM, highway networks actually utilize the gating mechanism to pass information almost unchanged through many layers.</p></div><p class="readmore"><a href="/CNNs-for-classification/Highway-Networks/">Read More</a></p></div><div class="post"><h1 class="post-title"><a href="/CNNs-for-classification/Batch-Normalization/">Batch-Normalization</a></h1><div class="post-meta">2019-05-30</div><div class="post-content"><p>paper: <a href="https://arxiv.org/pdf/1502.03167v3.pdf" target="_blank" rel="noopener">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</a>  </p></div><p class="readmore"><a href="/CNNs-for-classification/Batch-Normalization/">Read More</a></p></div><div class="post"><h1 class="post-title"><a href="/CNNs-for-classification/SKNet/">SKNet</a></h1><div class="post-meta">2019-05-30</div><div class="post-content"><p>paper: <a href="https://arxiv.org/pdf/1903.06586.pdf" target="_blank" rel="noopener">Selective Kernel Networks</a></p>
<p>It is well-known in the neuroscience community that the receptive field size of visual cortical neurons are modulated by the stimulus, which has been rarely considered in constructing CNNs. In Selective Kernel (SK) unit, multiple branches with different kernel sizes are fused using softmax attention that is guided by the information in these branches. </p></div><p class="readmore"><a href="/CNNs-for-classification/SKNet/">Read More</a></p></div><div class="post"><h1 class="post-title"><a href="/CNNs-for-classification/GoogLeNet/">GoogLeNet</a></h1><div class="post-meta">2019-05-25</div><div class="post-content"><p>paper: <a href="https://arxiv.org/pdf/1409.4842.pdf" target="_blank" rel="noopener">Going deeper with convolutions</a>  </p>
<p>The most straightforward way of improving the performance of deep neural networks is by increasing both their depth and width. But it makes a larger number of parameters which makes the enlarged network more prone to overfitting and increases use of computational resources. The fundamental way of solving both issues would be by ultimately moving from fully connected to sparsely connected architectures. But todays computing infrastructures are very inefficient when it comes to numerical calculation on non-uniform sparse data structures. how about an architecture that makes use of the extra sparsity, even at filter level, as suggested by GoogLeNet. It’s the winner of ILSVRC-2014 classification task.  </p></div><p class="readmore"><a href="/CNNs-for-classification/GoogLeNet/">Read More</a></p></div><div class="post"><h1 class="post-title"><a href="/CNNs-for-classification/VGG/">VGG</a></h1><div class="post-meta">2019-05-25</div><div class="post-content"><p>paper: <a href="https://arxiv.org/pdf/1409.1556.pdf" target="_blank" rel="noopener">VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION</a>  </p></div><p class="readmore"><a href="/CNNs-for-classification/VGG/">Read More</a></p></div><div class="post"><h1 class="post-title"><a href="/CNNs-for-classification/NIN/">NIN</a></h1><div class="post-meta">2019-05-25</div><div class="post-content"><p>paper: <a href="https://arxiv.org/pdf/1312.4400.pdf" target="_blank" rel="noopener">Network In Network</a>  </p>
<h3 id="Contributions"><a href="#Contributions" class="headerlink" title="Contributions"></a><strong>Contributions</strong></h3><ol></ol></div><p class="readmore"><a href="/CNNs-for-classification/NIN/">Read More</a></p></div><div class="post"><h1 class="post-title"><a href="/CNNs-for-classification/OverFeat/">OverFeat</a></h1><div class="post-meta">2019-05-21</div><div class="post-content"><p>paper: <a href="https://arxiv.org/pdf/1312.6229.pdf" target="_blank" rel="noopener">OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks</a></p></div><p class="readmore"><a href="/CNNs-for-classification/OverFeat/">Read More</a></p></div><nav class="page-navigator"><span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/">Next</a></nav><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"><input type="hidden" name="sitesearch" value="https://blog.dtrimina.cn"></form></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> Tags</i></div><div class="tagcloud"><a href="/tags/CNNs-for-detection/" style="font-size: 15px;">CNNs_for_detection</a> <a href="/tags/CNNs-for-classification/" style="font-size: 15px;">CNNs_for_classification</a> <a href="/tags/CNNs-for-localization/" style="font-size: 15px;">CNNs_for_localization</a> <a href="/tags/summary/" style="font-size: 15px;">summary</a> <a href="/tags/deep-learning-tools/" style="font-size: 15px;">deep-learning-tools</a> <a href="/tags/Segmentation/" style="font-size: 15px;">Segmentation</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> Recent</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/Segmentation/segmentation-1/">segmentation(1) -- FCN、DeconvNet</a></li><li class="post-list-item"><a class="post-list-link" href="/summary/CNN-architecture-summary/">Systematic evaluation of CNN advances on the ImageNet</a></li><li class="post-list-item"><a class="post-list-link" href="/CNNs-for-classification/SqueezeNet/">SqueezeNet</a></li><li class="post-list-item"><a class="post-list-link" href="/deep-learning-tools/Ubuntu18-04-deep-learning/">Ubuntu18.04 with deep learning (cuda10.0 + pytorch1.1 + tensorflow2.0.0-beta + mxnet)</a></li><li class="post-list-item"><a class="post-list-link" href="/CNNs-for-classification/Resnet/">Resnet</a></li><li class="post-list-item"><a class="post-list-link" href="/CNNs-for-detection/Fast-RCNN/">Fast R-CNN</a></li><li class="post-list-item"><a class="post-list-link" href="/CNNs-for-classification/SPP-net/">SPP-net</a></li><li class="post-list-item"><a class="post-list-link" href="/CNNs-for-classification/PReLU-nets/">PReLU-nets</a></li><li class="post-list-item"><a class="post-list-link" href="/CNNs-for-classification/Highway-Networks/">Highway Networks</a></li><li class="post-list-item"><a class="post-list-link" href="/CNNs-for-classification/Batch-Normalization/">Batch-Normalization</a></li></ul></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2019 <a href="/." rel="nofollow">LXY.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>